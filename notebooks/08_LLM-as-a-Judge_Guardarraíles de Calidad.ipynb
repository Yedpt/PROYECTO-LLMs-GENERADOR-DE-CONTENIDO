{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb998ede",
   "metadata": {},
   "source": [
    "# Notebook 08 ‚Äì LLM-as-a-Judge y Control de Calidad\n",
    "\n",
    "Objetivo:\n",
    "Implementar un sistema de evaluaci√≥n autom√°tica de las respuestas generadas\n",
    "para reducir alucinaciones y mejorar la calidad del contenido.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160b0c48",
   "metadata": {},
   "source": [
    "¬øQu√© es LLM-as-a-Judge?\n",
    "\n",
    "Usar un segundo LLM para:\n",
    "\n",
    "Evaluar la salida de otro LLM\n",
    "\n",
    "Aplicar criterios objetivos\n",
    "\n",
    "Tomar decisiones autom√°ticas\n",
    "\n",
    "üí° Ejemplos reales:\n",
    "\n",
    "Chatbots empresariales\n",
    "\n",
    "Copilots\n",
    "\n",
    "Sistemas cient√≠ficos\n",
    "\n",
    "Moderaci√≥n de contenido"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1ec709",
   "metadata": {},
   "source": [
    "üéØ CRITERIOS QUE VAMOS A USAR\n",
    "\n",
    "1Ô∏è‚É£ Claridad\n",
    "2Ô∏è‚É£ Correcci√≥n factual\n",
    "3Ô∏è‚É£ Utilidad para el usuario\n",
    "4Ô∏è‚É£ Adecuaci√≥n al contexto\n",
    "5Ô∏è‚É£ Riesgo de alucinaci√≥n\n",
    "\n",
    "PROMPT DEL JUEZ (TEOR√çA)\n",
    "\n",
    "Un buen juez:\n",
    "\n",
    "NO reescribe\n",
    "\n",
    "NO a√±ade contenido\n",
    "\n",
    "SOLO eval√∫a\n",
    "\n",
    "El output debe ser:\n",
    "\n",
    "estructurado\n",
    "\n",
    "f√°cil de parsear\n",
    "\n",
    "usable por c√≥digo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f0ed47",
   "metadata": {},
   "source": [
    "üìÅbackend/app/models/agents/judge_agent.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c669f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from app.models.llms.groq_llm import get_groq_llm\n",
    "\n",
    "llm = get_groq_llm()\n",
    "\n",
    "judge_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Eres un evaluador experto de contenido generado por IA.\n",
    "\n",
    "Eval√∫a la siguiente respuesta seg√∫n estos criterios:\n",
    "- Claridad\n",
    "- Correcci√≥n factual\n",
    "- Utilidad\n",
    "- Adecuaci√≥n al contexto\n",
    "- Riesgo de alucinaci√≥n\n",
    "\n",
    "Devuelve SOLO este formato:\n",
    "\n",
    "SCORE: <n√∫mero de 0 a 10>\n",
    "FEEDBACK: <breve explicaci√≥n>\n",
    "\n",
    "Pregunta original:\n",
    "{question}\n",
    "\n",
    "Respuesta generada:\n",
    "{answer}\n",
    "\"\"\")\n",
    "\n",
    "def evaluate_answer(question: str, answer: str) -> dict:\n",
    "    response = llm.invoke(\n",
    "        judge_prompt.format(\n",
    "            question=question,\n",
    "            answer=answer\n",
    "        )\n",
    "    )\n",
    "\n",
    "    text = response.content\n",
    "\n",
    "    score = 0\n",
    "    feedback = \"\"\n",
    "\n",
    "    for line in text.splitlines():\n",
    "        if line.startswith(\"SCORE\"):\n",
    "            score = int(line.split(\":\")[1].strip())\n",
    "        if line.startswith(\"FEEDBACK\"):\n",
    "            feedback = line.split(\":\")[1].strip()\n",
    "\n",
    "    return {\n",
    "        \"score\": score,\n",
    "        \"feedback\": feedback\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2fd1e5",
   "metadata": {},
   "source": [
    "INTEGRAR EL JUEZ EN EL SISTEMA\n",
    "\n",
    "Ahora vamos a usar el juez DESPU√âS de generar contenido."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f26e22",
   "metadata": {},
   "source": [
    "üìÅbackend/app/services/content_service.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a50a4d",
   "metadata": {},
   "source": [
    "üîÅ MODIFICA la funci√≥n generate_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9b1e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.models.agents.judge_agent import evaluate_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f10bb9",
   "metadata": {},
   "source": [
    "üìå A√±ade este import arriba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50190dc8",
   "metadata": {},
   "source": [
    "üîÅ REEMPLAZA la funci√≥n generate_content por esta versi√≥n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa9e793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_content(question: str) -> dict:\n",
    "    memory.add(\"user\", question)\n",
    "\n",
    "    strategy = route(question)\n",
    "\n",
    "    if strategy == \"graph_rag\":\n",
    "        answer = graph_rag_answer(\n",
    "            text=question,\n",
    "            question=question\n",
    "        )\n",
    "    elif strategy == \"multiagent\":\n",
    "        answer = marketing_agent(question)\n",
    "    else:\n",
    "        answer = rag_answer(question)\n",
    "\n",
    "    evaluation = evaluate_answer(question, answer)\n",
    "\n",
    "    memory.add(\"assistant\", answer)\n",
    "\n",
    "    return {\n",
    "        \"answer\": answer,\n",
    "        \"evaluation\": evaluation,\n",
    "        \"strategy_used\": strategy\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da9b74c",
   "metadata": {},
   "source": [
    "QU√â HEMOS CONSEGUIDO\n",
    "\n",
    "Ahora tu sistema:\n",
    "\n",
    "‚úÖ Genera contenido\n",
    "‚úÖ Decide estrategia\n",
    "‚úÖ Eval√∫a su propia calidad\n",
    "‚úÖ Devuelve m√©tricas\n",
    "‚úÖ Reduce alucinaciones\n",
    "\n",
    "Esto ya es:\n",
    "\n",
    "Arquitectura de IA responsable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565a78b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"answer\": \"La inteligencia artificial es...\",\n",
    "  \"evaluation\": {\n",
    "    \"score\": 8,\n",
    "    \"feedback\": \"Respuesta clara y bien estructurada, aunque podr√≠a profundizar m√°s en ejemplos.\"\n",
    "  },\n",
    "  \"strategy_used\": \"rag\"\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
